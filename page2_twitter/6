# page2_news.py
import re
import streamlit as st
from streamlit.components.v1 import html as html_component
from db import fetch_df  # ← relative import, per your note

# --- helpers ---------------------------------------------------------------

def _normalize(u: str) -> str:
    # x.com → twitter.com is more reliable for widgets.js
    return re.sub(r"^https?://x\.com/", "https://twitter.com/", u.strip())

@st.cache_data(ttl=600, show_spinner=False)
def _total_tweet_count() -> int:
    df = fetch_df("""
        SELECT COUNT(*) AS N
        FROM MART.TWEET_MEDIA
        WHERE TWEET_URL IS NOT NULL
    """)
    return int(df["N"].iloc[0])

@st.cache_data(ttl=120, show_spinner=False)
def _get_urls(limit: int, offset: int) -> list[str]:
    df = fetch_df(f"""
        SELECT TWEET_URL
        FROM MART.TWEET_MEDIA
        WHERE TWEET_URL IS NOT NULL
        ORDER BY CREATED_AT DESC
        LIMIT {int(limit)} OFFSET {int(offset)}
    """)
    return [_normalize(str(u)) for u in df["TWEET_URL"].dropna().astype(str)]

def _render_embeds(urls: list[str], theme: str = "dark") -> None:
    # One iframe with all blockquotes + a single widgets.js include
    blockquotes = "\n".join(
        [f'<blockquote class="twitter-tweet" data-theme="{theme}"><a href="{u}"></a></blockquote>'
         for u in urls]
    )
    html = f"""
    <!doctype html><meta charset="utf-8"/>
    <div id="wrap" style="max-width: 650px; margin: 0 auto;">
      {blockquotes}
    </div>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
    """
    # Rough height per tweet so the whole set fits; allow iframe scrolling as needed
    height = min(120 + 680 * max(1, len(urls)), 5000)
    html_component(html, height=height, scrolling=True)

# --- page UI ---------------------------------------------------------------

def main():
    st.set_page_config(layout="wide")
    st.subheader("Trending Social Posts")

    # Controls
    col1, col2, col3, col4, col5 = st.columns([1,1,1,1,2])
    with col1:
        page_size = st.selectbox("Page size", [5, 10, 15], index=1, key="news_page_size")
    with col2:
        theme = st.selectbox("Theme", ["dark", "light"], index=0, key="news_theme")
    with col3:
        mode_append = st.toggle("Append mode", value=False, help="If on, 'Next' adds 10 more below (load more).")
    with col4:
        if st.button("Refresh list"):
            st.cache_data.clear()
            st.rerun()
    with col5:
        total = _total_tweet_count()
        st.markdown(f"<div style='margin-top:16px;color:#888'>Total: {total:,}</div>", unsafe_allow_html=True)

    # Session state for pagination/append
    if "news_offset" not in st.session_state:
        st.session_state.news_offset = 0
    if "news_accum_urls" not in st.session_state:
        st.session_state.news_accum_urls = []

    # Nav buttons
    nav1, nav2, nav3 = st.columns([1,1,3])
    with nav1:
        disabled_prev = st.session_state.news_offset <= 0
        if st.button("◀ Prev", disabled=disabled_prev):
            st.session_state.news_offset = max(0, st.session_state.news_offset - page_size)
            if not mode_append:
                st.session_state.news_accum_urls = []
            st.rerun()
    with nav2:
        disabled_next = (st.session_state.news_offset + page_size) >= total
        if st.button("Next ▶", disabled=disabled_next):
            if mode_append:
                # keep current offset for next slice and accumulate
                pass
            else:
                st.session_state.news_accum_urls = []
            st.session_state.news_offset = min(total, st.session_state.news_offset + page_size)
            st.rerun()
    with nav3:
        max_page = max(1, (total + page_size - 1) // page_size)
        cur_page = st.number_input(
            "Jump to page", min_value=1, max_value=max_page,
            value=(st.session_state.news_offset // page_size) + 1, step=1
        )
        if cur_page != (st.session_state.news_offset // page_size) + 1:
            st.session_state.news_offset = (int(cur_page) - 1) * page_size
            if not mode_append:
                st.session_state.news_accum_urls = []
            st.rerun()

    # Fetch URLs for current slice
    cur_urls = _get_urls(limit=page_size, offset=st.session_state.news_offset)

    # Append vs paginate
    if mode_append:
        # Accumulate (dedupe while preserving order)
        seen = set(st.session_state.news_accum_urls)
        for u in cur_urls:
            if u not in seen:
                st.session_state.news_accum_urls.append(u); seen.add(u)
        urls_to_render = st.session_state.news_accum_urls
    else:
        urls_to_render = cur_urls

    st.caption(f"Showing {len(urls_to_render)} tweet(s) "
               f"[page size {page_size}, offset {st.session_state.news_offset}]")

    # Render embeds
    if urls_to_render:
        _render_embeds(urls_to_render, theme=theme)
    else:
        st.info("No tweets to show.")

# # For direct run (optional)
# if __name__ == "__main__":
#     ()
